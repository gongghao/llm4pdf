0703  
1发现使用PyMuPDF提取文字会存在在涉及Latex公式等场景出现文字格式混乱的情况，考虑改变思路采用视觉大模型识别  
2发现原文引用效果不好，考虑可能是分块的策略问题，原本是单纯提取文字和图片，现在改用采取版面分析的方法进行pdf分析，生成每一页各个区域类别、位置和阅读顺序信息paddleocr的PPStructure模型  
- Unstructured[3]：它已集成到langchain中[4]。使用hi_res策略设置infer_table_structure=True可以很好的识别表格信息。然而，fast策略因为不使用目标检测模型，在识别图像和表格方面表现较差。
- Layout-parser[5]：如果需要识别复杂的结构化PDF，建议使用最大的模型以获得更高的精度，尽管它可能会稍微慢一些。此外，Layout解析器的模型[6]在过去两年中似乎没有更新。
- PP-StructureV2[7]：可以组合各种模型用于文档分析，性能高于平均水平。体系结构如图4所示：

0704
目前问题与原文匹配采用关键词匹配的方法，考虑采用将文字根据LLM的上下文约束切分后向量化存储到向量数据库，进而根据用户的问题召回相关内容，将相关内容送给LLM生成回复，另一方面用MR将切分文字直接送给LLM进行总结  
今日解决上下文切分部分（chunking），本项目的文本是以markdown形式进行存储的，且要考虑到用户问题通常是较为简单的，可以基于此去寻找合适的chunking方法，考虑采用混合分块：首先尝试基于文档结构进行高级别分割，然后在这些较大的分割快内部使用递归字符分块或句子分块进行细粒度的切分，借鉴茴香豆项目的部分思路，并进行简化与改造，确定rag部分使用langchain
0707 遇到paddle与torch的冲突问题
解决https://github.com/PaddlePaddle/Paddle/issues/66947
没办法解决，放弃使用paddle，使用vlm（qwen）进行pdf解析提取，目前又面临图片的准确提取问题，向量化存储和图片描述解决
0708
向量化部分改进，chunk部分细化，qwen改用流式输出避免超时问题